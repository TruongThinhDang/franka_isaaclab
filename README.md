# Franka Robot Manipulation with Isaac Lab

<div align="center">

![Python](https://img.shields.io/badge/python-3.8+-blue.svg)
![Isaac Lab](https://img.shields.io/badge/Isaac%20Lab-Latest-green.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)
![License](https://img.shields.io/badge/license-BSD--3-blue.svg)

*A comprehensive reinforcement learning project for robotic manipulation using the Franka Emika Panda robot*

[Features](#-features) â€¢ [Installation](#-installation) â€¢ [Usage](#-usage) â€¢ [Tasks](#-tasks) â€¢ [Results](#-results)

</div>

---

## ğŸ¯ Project Overview

This project implements three progressive manipulation tasks for the **Franka Emika Panda** robot using **Deep Reinforcement Learning** in NVIDIA Isaac Lab. The tasks increase in complexity, demonstrating the robot's ability to perform increasingly sophisticated manipulation skills.

### Implemented Tasks

| Task | Description | Complexity | Status |
|------|-------------|------------|--------|
| **Reach** | Navigate end-effector to target positions in 3D space | â­ Basic | âœ… Completed |
| **Lift** | Grasp and lift a cube to a target height | â­â­ Intermediate | âœ… Completed |
| **Stack** | Pick and stack multiple cubes on top of each other | â­â­â­ Advanced | âœ… Completed |

## âœ¨ Features

- **ğŸ¤– Custom Robot Environments**: Tailored configurations for Franka Panda robot
- **ğŸ“ Progressive Learning**: Three tasks with increasing difficulty
- **ğŸ† Reward Engineering**: Carefully designed reward functions with stage-based curriculum
- **ğŸ’¾ Checkpoint Management**: Automatic saving of best performing agents
- **ğŸ“Š TensorBoard Integration**: Real-time training monitoring
- **âš¡ GPU-Accelerated**: Leveraging NVIDIA Isaac Sim's physics engine
- **ğŸ”§ Modular Design**: Clean separation of MDPs (observations, rewards, terminations)

## ğŸ› ï¸ Installation

### Prerequisites

- **NVIDIA Isaac Lab** (see [installation guide](https://isaac-sim.github.io/IsaacLab/main/source/setup/installation/index.html))
- **Python** 3.8 or higher
- **CUDA-capable GPU** (recommended: RTX 3060 or better)
- **Ubuntu** 20.04+ or equivalent Linux distribution

### Setup Steps

1. **Clone the repository**
   ```bash
   git clone https://github.com/TruongThinhDang/franka_isaaclab.git
   cd franka_isaaclab
   ```

2. **Install the package**
   ```bash
   # If using Isaac Lab's conda environment
   python -m pip install -e source/franka_isaaclab
   
   # Or using Isaac Lab's shell wrapper
   # ./isaaclab.sh -p -m pip install -e source/franka_isaaclab
   ```

3. **Verify installation**
   ```bash
   python scripts/list_envs.py
   ```

## ğŸ® Usage

### Training

Train different tasks using the SKRL PPO implementation:

```bash
# Train the Reach task
python scripts/skrl/train.py --task=Template-Reach-v0

# Train the Lift task
python scripts/skrl/train.py --task=Template-Lift-v0

# Train the Stack task
python scripts/skrl/train.py --task=Template-Stack-v0
```

**Training arguments:**
- `--task`: Environment ID to train
- `--num_envs`: Number of parallel environments (default: varies by task)
- `--seed`: Random seed for reproducibility

### Inference

Test trained models in play mode:

```bash
# Play with trained Lift model
python scripts/skrl/play.py --task=Template-Lift-Play-v0 \
    --checkpoint=logs/skrl/franka_lift/*/checkpoints/best_agent.pt

# Play with trained Stack model
python scripts/skrl/play.py --task=Template-Stack-Play-v0 \
    --checkpoint=logs/skrl/franka_stack/*/checkpoints/best_agent.pt
```

### Environment Testing

Test environments with dummy agents:

```bash
# Test with random actions
python scripts/random_agent.py --task=Template-Lift-v0 --num_envs=16

# Test with zero actions (useful for debugging)
python scripts/zero_agent.py --task=Template-Lift-v0 --num_envs=16
```

## ğŸ“š Tasks

### 1. Reach Task (`Template-Reach-v0`)

**Objective:** Move the end-effector to a randomly placed target position.

- **Observation Space:** 24 dimensions (joint positions/velocities, end-effector pose, target position)
- **Action Space:** 7 dimensions (joint position commands)
- **Reward Components:**
  - Distance to target (tanh-kernel)
  - Action penalties
- **Training Time:** ~24,000 timesteps

### 2. Lift Task (`Template-Lift-v0`)

**Objective:** Grasp a cube and lift it above a target height.

- **Observation Space:** Joint states + cube position/orientation + end-effector pose
- **Action Space:** 7 joint positions + gripper command
- **Reward Components:**
  - End-effector to object distance
  - Object lift height reward
  - Grasp stability bonus
  - Action smoothness penalty
- **Training Time:** ~36,000 timesteps
- **Success Criteria:** Cube lifted > 0.5m for sustained period

### 3. Stack Task (`Template-Stack-v0`)

**Objective:** Pick up cube 1 and stack it on top of cube 2.

- **Observation Space:** Joint states + 2 cube poses + end-effector pose
- **Action Space:** 7 joint positions + gripper command
- **Multi-Stage Reward System:**
  1. **Stage 1:** Reach cube 1
  2. **Stage 2:** Grasp and lift cube 1
  3. **Stage 3:** Move cube 1 towards cube 2
  4. **Stage 4:** Align and stack cubes
  5. **Stage 5:** Release and verify stack stability
- **Training Time:** ~36,000+ timesteps
- **Advanced Features:**
  - Custom event handlers for grasp detection
  - Stage-based curriculum learning
  - Stack stability verification

## ğŸ“Š Results

### Training Performance

| Task | Total Steps | Best Reward | Success Rate | Checkpoint |
|------|-------------|-------------|--------------|------------|
| Reach | 24,000 | N/A | High | âœ… Available |
| Lift | 36,000 | N/A | High | âœ… Available |
| Stack | 36,000+ | N/A | Progressive | âœ… Available |

### Trained Models

Pre-trained checkpoints are available in `logs/skrl/`:

```
logs/skrl/
â”œâ”€â”€ reach_franka/2025-12-06_19-58-37_ppo_torch/
â”‚   â””â”€â”€ checkpoints/best_agent.pt
â”œâ”€â”€ franka_lift/2025-12-07_19-34-59_ppo_torch/
â”‚   â””â”€â”€ checkpoints/best_agent.pt
â””â”€â”€ (Additional training runs...)
```

## ğŸ—ï¸ Project Structure

```
franka_isaaclab/
â”œâ”€â”€ source/franka_isaaclab/
â”‚   â””â”€â”€ franka_isaaclab/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ assets/
â”‚       â”‚   â””â”€â”€ robots/
â”‚       â”‚       â””â”€â”€ franka.py          # Franka robot configuration
â”‚       â””â”€â”€ tasks/
â”‚           â””â”€â”€ manager_based/
â”‚               â”œâ”€â”€ reach/             # Reach task
â”‚               â”‚   â”œâ”€â”€ joint_pos_env_cfg.py
â”‚               â”‚   â”œâ”€â”€ reach_env_cfg.py
â”‚               â”‚   â”œâ”€â”€ agents/
â”‚               â”‚   â”‚   â””â”€â”€ skrl_ppo_cfg.yaml
â”‚               â”‚   â””â”€â”€ mdp/
â”‚               â”‚       â””â”€â”€ rewards.py
â”‚               â”œâ”€â”€ lift/              # Lift task
â”‚               â”‚   â”œâ”€â”€ joint_pos_env_cfg.py
â”‚               â”‚   â”œâ”€â”€ lift_env_cfg.py
â”‚               â”‚   â”œâ”€â”€ agents/
â”‚               â”‚   â”‚   â””â”€â”€ skrl_ppo_cfg.yaml
â”‚               â”‚   â””â”€â”€ mdp/
â”‚               â”‚       â”œâ”€â”€ observations.py
â”‚               â”‚       â”œâ”€â”€ rewards.py
â”‚               â”‚       â””â”€â”€ terminations.py
â”‚               â””â”€â”€ stack/             # Stack task
â”‚                   â”œâ”€â”€ stack_joint_pos_env_cfg.py
â”‚                   â”œâ”€â”€ stack_env_cfg.py
â”‚                   â”œâ”€â”€ agents/
â”‚                   â”‚   â””â”€â”€ skrl_ppo_cfg.yaml
â”‚                   â””â”€â”€ mdp/
â”‚                       â”œâ”€â”€ franka_stack_events.py
â”‚                       â”œâ”€â”€ observations.py
â”‚                       â”œâ”€â”€ rewards.py
â”‚                       â””â”€â”€ terminations.py
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ list_envs.py
â”‚   â”œâ”€â”€ random_agent.py
â”‚   â”œâ”€â”€ zero_agent.py
â”‚   â””â”€â”€ skrl/
â”‚       â”œâ”€â”€ train.py
â”‚       â””â”€â”€ play.py
â”œâ”€â”€ logs/                              # Training logs and checkpoints
â”œâ”€â”€ outputs/                           # Hydra outputs
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## ğŸ”¬ Technical Details

### MDP Components

Each task is decomposed into modular MDP components:

- **Observations** (`mdp/observations.py`): Custom observation functions
- **Rewards** (`mdp/rewards.py`): Multi-stage reward shaping
- **Terminations** (`mdp/terminations.py`): Success/failure conditions
- **Events** (`mdp/*_events.py`): Custom event handlers (e.g., grasp detection)

### PPO Configuration

Training uses Proximal Policy Optimization (PPO) via SKRL:

- **Policy Network:** Multi-layer perceptron (configurable)
- **Learning Rate:** Adaptive with scheduler
- **Batch Size:** Optimized per task
- **Parallel Environments:** 16-64 environments simultaneously
- **GPU Acceleration:** Full physics and neural network on GPU

## ğŸ“ Key Learning Outcomes

This project demonstrates:

1. âœ… **Custom RL Environment Design** in Isaac Lab framework
2. âœ… **Reward Engineering** for complex manipulation tasks
3. âœ… **Curriculum Learning** with progressive task difficulty
4. âœ… **Multi-Stage Task Decomposition** for the stacking problem
5. âœ… **Integration** with modern RL libraries (SKRL, Gymnasium)
6. âœ… **GPU-Accelerated Simulation** for fast training
7. âœ… **Checkpoint Management** and model versioning

## ğŸ”§ Customization

### Creating New Tasks

1. Create new task directory in `source/franka_isaaclab/franka_isaaclab/tasks/manager_based/`
2. Define environment configuration (`*_env_cfg.py`)
3. Implement MDP components in `mdp/` directory
4. Register environment in `__init__.py`
5. Add PPO configuration in `agents/skrl_ppo_cfg.yaml`

### Modifying Rewards

Edit reward functions in `mdp/rewards.py` for each task. All rewards use the Isaac Lab manager-based interface.

## ğŸ“ License

This project is licensed under the BSD-3-Clause License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- Built on [NVIDIA Isaac Lab](https://github.com/isaac-sim/IsaacLab)
- Reinforcement learning via [SKRL](https://github.com/Toni-SM/skrl)
- Inspired by robotic manipulation research and IsaacLab tutorials

## ğŸ“§ Contact

**Truong Thinh Dang**

- GitHub: [@TruongThinhDang](https://github.com/TruongThinhDang)
- Project Link: [https://github.com/TruongThinhDang/franka_isaaclab](https://github.com/TruongThinhDang/franka_isaaclab)

---

<div align="center">

**â­ If you find this project useful, please consider giving it a star! â­**

</div>
